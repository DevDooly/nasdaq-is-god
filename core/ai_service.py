import os
import google.generativeai as genai
import json
import logging
import time
import httpx
from datetime import datetime
from typing import List, Dict, Any, Optional

logger = logging.getLogger("ai_service")

class AIService:
    def __init__(self):
        self.default_api_key = os.getenv("GEMINI_API_KEY")
        if self.default_api_key and self.default_api_key != "your_gemini_api_key_here":
            genai.configure(api_key=self.default_api_key)
        
        self._market_cache = None
        self._market_cache_time = 0
        self.CACHE_DURATION = 1800 

    def list_available_models(self, api_key: Optional[str] = None) -> List[Dict[str, str]]:
        # ìƒëµ (ê¸°ì¡´ ë¡œì§ ìœ ì§€í•˜ë˜ í•„ìš” ì‹œ í™•ì¥)
        return [{"name": "models/gemini-2.0-flash", "display_name": "Gemini 2.0 Flash"},
                {"name": "llama3", "display_name": "Ollama: Llama3"}]

    async def analyze_sentiment_with_rotation(self, symbol: str, news_list: List[Dict[str, Any]], api_configs: List[Dict[str, Any]], model_name: str = "models/gemini-2.0-flash") -> Dict[str, Any]:
        """
        í™œì„±í™”ëœ AI ì„¤ì •ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (ë©€í‹° í”„ë¡œë°”ì´ë” ì§€ì›)
        """
        # 1. í™œì„± ì„¤ì • ì°¾ê¸°
        active_config = next((c for c in api_configs if c['is_active']), None)
        if not active_config:
            # í™œì„± ì„¤ì • ì—†ìœ¼ë©´ ENVì˜ Gemini ì‚¬ìš©
            if not self.default_api_key: return {"error": "No Active AI Config."}
            active_config = {"provider": "GOOGLE", "key_value": self.default_api_key, "id": None, "label": "Default ENV"}

        provider = active_config.get("provider", "GOOGLE").upper()
        prompt = self._build_sentiment_prompt(f"ì£¼ì‹ ì¢…ëª© '{symbol}'", news_list)

        # 2. í”„ë¡œë°”ì´ë”ë³„ ë“œë¼ì´ë²„ í˜¸ì¶œ
        try:
            if provider == "OLLAMA":
                result = await self._call_ollama(active_config["base_url"], model_name, prompt)
            elif provider == "GOOGLE":
                result = await self._call_google(active_config["key_value"], model_name, prompt)
            elif provider == "OPENAI":
                result = await self._call_openai(active_config["key_value"], model_name, prompt)
            else:
                return {"error": f"Unsupported provider: {provider}"}
            
            if "error" not in result:
                result["used_key_id"] = active_config.get("id")
                result["sources"] = [n.get('title') for n in news_list[:10] if n.get('title')]
            return result
        except Exception as e:
            return {"error": str(e)}

    def _build_sentiment_prompt(self, target: str, news_list: List[Dict[str, Any]]) -> str:
        titles = [n.get('title', '') for n in news_list[:10]]
        news_text = "\n".join([f"- {t}" for t in titles if t])
        return f"""
        ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ í€€íŠ¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. {target} ìµœì‹  ë‰´ìŠ¤ ë¶„ì„:
        {news_text}
        ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤:
        {{ "score": 0~100, "sentiment": "Bullish|Bearish|Neutral", "summary": "í•œêµ­ì–´ ìš”ì•½", "reason": "í•œêµ­ì–´ ì´ìœ " }}
        """

    async def _call_ollama(self, base_url: str, model: str, prompt: str) -> Dict[str, Any]:
        """Ollama API í˜¸ì¶œ (ë¡œì»¬/ì›ê²©)"""
        if not base_url: return {"error": "Ollama base_url is missing"}
        # http:// ì¶”ê°€ ì²´í¬
        if not base_url.startswith("http"): base_url = f"http://{base_url}"
        
        # ëª¨ë¸ëª… ë³´ì • (Gemini ê¸°ë³¸ê°’ì´ ë„˜ì–´ì˜¬ ê²½ìš° llama3ë¡œ ëŒ€ì²´)
        ollama_model = "llama3" if "gemini" in model else model
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            try:
                response = await client.post(
                    f"{base_url}/api/generate",
                    json={
                        "model": ollama_model,
                        "prompt": prompt,
                        "stream": False,
                        "format": "json"
                    }
                )
                if response.status_code != 200:
                    return {"error": f"Ollama Error: {response.text}"}
                
                res_data = response.json()
                return json.loads(res_data["response"])
            except Exception as e:
                return {"error": f"Ollama Connection Failed: {str(e)}"}

    async def _call_google(self, api_key: str, model_name: str, prompt: str) -> Dict[str, Any]:
        """ê¸°ì¡´ Gemini í˜¸ì¶œ ë¡œì§"""
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        # run_in_executorë¡œ ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(None, lambda: model.generate_content(prompt))
        text = response.text.strip()
        if "```json" in text: text = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text: text = text.split("```")[1].split("```")[0].strip()
        return json.loads(text)

    async def _call_openai(self, api_key: str, model: str, prompt: str) -> Dict[str, Any]:
        # OpenAI SDK ì—°ë™ (ìƒëµ - í–¥í›„ í•„ìš” ì‹œ ì¶”ê°€)
        return {"error": "OpenAI driver not implemented yet"}

    async def analyze_social_impact(self, guru_name: str, content: str, target_symbols: str = "", model_name: str = "models/gemini-2.0-flash") -> Dict[str, Any]:
        # ğŸ’¡ Webhook ë“±ì—ì„œ í˜¸ì¶œë˜ëŠ” ì†Œì…œ ë¶„ì„ë„ ë©€í‹° í”„ë¡œë°”ì´ë” ì ìš©ì´ í•„ìš”í•¨
        # ìš°ì„  ê¸°ì¡´ ë¡œì§ ìœ ì§€í•˜ë˜ Gemini API Key ë¡œë“œ ë°©ì‹ë§Œ ë³´ì •
        prompt = f"""
        ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ì˜ ì‹œë‹ˆì–´ í€€íŠ¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. 
        ì‹œì¥ ì˜í–¥ë ¥ì´ í° ì¸ë¬¼ '{guru_name}'ì˜ ìµœê·¼ ë°œì–¸ì„ ë¶„ì„í•˜ì—¬ ì£¼ì‹ ì‹œì¥ì— ë¯¸ì¹  íŒŒê¸‰ë ¥ì„ í‰ê°€í•˜ì‹­ì‹œì˜¤.
        [ë°œì–¸ ì›ë¬¸]: "{content}"
        í˜•ì‹ JSON: {{ "score": 0~100, "sentiment": "Bullish|Bearish|Neutral", "summary": "ìš”ì•½", "reason": "ì´ìœ ", "main_symbol": "í‹°ì»¤" }}
        """
        # ì—¬ê¸°ë„ ìœ„ ë“œë¼ì´ë²„ êµ¬ì¡°ë¥¼ íƒ€ê²Œ í•  ìˆ˜ ìˆìŒ (ë¦¬íŒ©í† ë§ ëŒ€ìƒ)
        return await self._call_google(self.default_api_key, model_name, prompt)

    async def analyze_market_outlook(self, news_list: List[Dict[str, Any]], model_name: str = "models/gemini-2.0-flash") -> Dict[str, Any]:
        current_time = time.time()
        if self._market_cache and (current_time - self._market_cache_time < self.CACHE_DURATION):
            return self._market_cache
        
        prompt = self._build_sentiment_prompt("ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ ì „ì²´", news_list)
        result = await self._call_google(self.default_api_key, model_name, prompt)
        
        if "error" not in result:
            self._market_cache = result
            self._market_cache_time = current_time
        return result

    async def check_provider_health(self, provider: str, base_url: Optional[str] = None, api_key: Optional[str] = None) -> bool:
        """AI í”„ë¡œë°”ì´ë”ì˜ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            if provider.upper() == "OLLAMA":
                if not base_url: return False
                if not base_url.startswith("http"): base_url = f"http://{base_url}"
                async with httpx.AsyncClient(timeout=5.0) as client:
                    response = await client.get(f"{base_url}/")
                    return response.status_code == 200
            elif provider.upper() == "GOOGLE":
                # ë‹¨ìˆœ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì • ì²´í¬
                return api_key is not None and len(api_key) > 10
            # OpenAI ë“± íƒ€ í”„ë¡œë°”ì´ë” í™•ì¥ ê°€ëŠ¥
            return True
        except Exception as e:
            logger.error(f"Health check failed for {provider}: {e}")
            return False